% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/subtyper.R
\name{assess_idp_consistency}
\alias{assess_idp_consistency}
\title{Assess neuroscientific consistency between IDPs and performance domains (Optimized)}
\usage{
assess_idp_consistency(
  df,
  Perf.Dom,
  idp_cols,
  backend = c("groq", "openrouter"),
  api_key_env = NULL,
  model = NULL,
  max_retries = 5,
  retry_delay_base = 2,
  temperature = 0.1,
  user_input_prompt =
    "Assess the neuroscientific consistency and provide a score (low, medium, high) and justification. ",
  verbose = TRUE,
  parallel = FALSE,
  .options_furrr = furrr::furrr_options()
)
}
\arguments{
\item{df}{A data frame containing at least the performance domain column and one or more IDP columns.}

\item{Perf.Dom}{Character string, name of the column in \code{df} containing the performance domain.}

\item{idp_cols}{Character vector of column names containing IDPs (e.g., \code{c("IDP.1","IDP.2")}).}

\item{backend}{Character string specifying which API backend to use: \code{"groq"} or \code{"openrouter"}.}

\item{api_key_env}{Character string, name of the environment variable storing the API key for the chosen backend.}

\item{model}{Character string, model name for the chosen backend. Defaults to \code{"llama3-70b-8192"} for Groq and \code{"openai/gpt-4o-mini"} for OpenRouter.}

\item{max_retries}{Integer, maximum number of retries in case of rate limiting.}

\item{retry_delay_base}{Numeric, base delay in seconds for exponential backoff (e.g., 1 for 1, 2, 4, 8s).}

\item{temperature}{Numeric, sampling temperature for the LLM. 0 for deterministic, higher for more creative. (0-1)}

\item{user_input_prompt}{refined with this user input.}

\item{verbose}{Logical, if \code{TRUE} prints progress and debugging information.}

\item{parallel}{Logical, if \code{TRUE} uses \code{furrr} for parallel API calls.}

\item{.options_furrr}{List, optional arguments passed to \code{furrr::future_map} (e.g., \code{future::plan()}).}

\item{prompt}{the default prompt}
}
\value{
A data frame with the original data plus:
\itemize{
\item \code{consistency_score} - numeric confidence score (0-100).
\item \code{justification} - short justification from the model.
}
}
\description{
This function queries a large language model via either the Groq API or OpenRouter API
to assess the neuroscientific support for the relationship between imaging-derived
phenotypes (IDPs) and a cognitive performance domain. It aggregates multiple IDPs per row
and provides an overall confidence score and justification.
}
\examples{
\dontrun{
# Before running, set your API key:
# Sys.setenv(GROQ_API_KEY = "YOUR_GROQ_API_KEY")
# Sys.setenv(OPENROUTER_API_KEY = "YOUR_OPENROUTER_API_KEY")

# Set up a plan for parallel processing (e.g., multicore)
# This line should be run once in your R session before calling the function with parallel = TRUE
future::plan(future::multisession, workers = 2) # Use 2 cores for parallel processing

df <- data.frame(
  PC_Name = c("PC-6", "PC-10", "PC-3"),
  Perf.Dom = c("working.memory", "recall.total", "attention.sustained"),
  IDP.1 = c("t1.vol.sup.frontal.ctx", "t1.vol.inf.parietal.ctx", "dt.fa.corpus.callosum"),
  IDP.2 = c("t1.vol.occipital.ctx", "t1.vol.hippocampus", "rsf.connect.dlpfc"),
  stringsAsFactors = FALSE
)

# Example usage (assuming GROQ_API_KEY is set)
results_groq <- assess_idp_consistency_optimized(
  df,
  Perf.Dom = "Perf.Dom",
  idp_cols = c("IDP.1", "IDP.2"),
  backend = "groq",
  api_key_env = "GROQ_API_KEY",
  parallel = TRUE # Use parallel processing
)
print(results_groq)

# OpenRouter example (assuming OPENROUTER_API_KEY is set)
# results_openrouter <- assess_idp_consistency_optimized(
#   df,
#   Perf.Dom = "Perf.Dom",
#   idp_cols = c("IDP.1", "IDP.2"),
#   backend = "openrouter",
#   api_key_env = "OPENROUTER_API_KEY",
#   model = "openai/gpt-4o-mini",
#   parallel = TRUE
# )
# print(results_openrouter)

# Clean up the future plan if no longer needed
future::plan(future::sequential)
}

}
