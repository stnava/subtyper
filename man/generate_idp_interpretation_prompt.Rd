% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/subtyper.R
\name{generate_idp_interpretation_prompt}
\alias{generate_idp_interpretation_prompt}
\title{Generate a Prompt for Interpreting Brain–Behavior Associations}
\usage{
generate_idp_interpretation_prompt(
  response_length = c("short", "medium", "long"),
  tone = c("neutral", "skeptical", "critical"),
  n_examples = 3
)

generate_idp_interpretation_prompt(
  response_length = c("short", "medium", "long"),
  tone = c("neutral", "skeptical", "critical"),
  n_examples = 3
)
}
\arguments{
\item{response_length}{Character. Desired length of justification.
One of: "short" (2–3 sentences), "medium" (3–6), "long" (5–8).}

\item{tone}{Character. Interpretive stance. One of:
"neutral", "skeptical", "critical".}

\item{n_examples}{Integer. Number of exemplar cases to include (0–5).}
}
\value{
A character string containing the full prompt.

A character string containing the full prompt.
}
\description{
This function constructs a standardized prompt for guiding large language models
in the interpretation of statistical associations between imaging-derived
phenotypes (IDPs) and human performance measures. The generated prompt enforces
strict JSON-only output with exactly two keys: \code{"consistency"} and
\code{"justification"}.

Constructs a standardized prompt for guiding large language models
in interpreting statistical associations between imaging-derived
phenotypes (IDPs) and human performance measures.
}
\details{
The model is required to return a strict JSON object with exactly
three keys:
\itemize{
\item "consistency"   : low / medium / high
\item "justification" : academic explanation
\item "plausibility"  : continuous numeric score between zero and one \link{0.0–1.0}
}
}
\examples{
# Generate a medium-length, skeptical prompt with 2 exemplars
cat(generate_idp_interpretation_prompt(
  response_length = "medium",
  tone = "skeptical",
  n_examples = 2
))

# Generate a long, critical prompt without exemplars
cat(generate_idp_interpretation_prompt(
  response_length = "long",
  tone = "critical",
  n_examples = 0
))

}
